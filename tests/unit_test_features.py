# -*- coding: utf-8 -*-
"""
LivePilotAI Day 4 æ¸¬è©¦è…³æœ¬
æ¸¬è©¦å³æ™‚äººè‡‰æª¢æ¸¬å’Œæƒ…æ„Ÿè­˜åˆ¥åŠŸèƒ½
"""

import sys
import os
import time
import logging
from pathlib import Path

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_camera_manager():
    """æ¸¬è©¦æ”åƒé ­ç®¡ç†å™¨"""
    logger.info("=== æ¸¬è©¦æ”åƒé ­ç®¡ç†å™¨ ===")
    
    try:
        from src.ai_engine.modules.camera_manager import CameraManager, CameraConfig
        
        # å‰µå»ºæ”åƒé ­é…ç½®
        config = CameraConfig(
            device_id=0,
            width=640,
            height=480,
            fps=30
        )
        
        # åˆå§‹åŒ–æ”åƒé ­ç®¡ç†å™¨
        camera = CameraManager(config)
        
        # æ¸¬è©¦åˆå§‹åŒ–
        if camera.initialize_camera():
            logger.info("âœ“ æ”åƒé ­åˆå§‹åŒ–æˆåŠŸ")
            
            # æ¸¬è©¦åŸºæœ¬è®€å–
            success, frame = camera.read_frame()
            if success:
                logger.info("âœ“ æ”åƒé ­è®€å–æ¸¬è©¦æˆåŠŸ")
                logger.info(f"  - å¹€å°ºå¯¸: {frame.shape}")
            else:
                logger.error("âœ— æ”åƒé ­è®€å–æ¸¬è©¦å¤±æ•—")
            
            # æ¸¬è©¦æ”åƒé ­ä¿¡æ¯
            info = camera.get_camera_info()
            logger.info(f"âœ“ æ”åƒé ­ä¿¡æ¯: {info}")
            
            # æ¸¬è©¦å³æ™‚æ•ç²
            logger.info("æ¸¬è©¦å³æ™‚æ•ç²æ¨¡å¼...")
            frame_count = 0
            
            def frame_callback(frame):
                nonlocal frame_count
                frame_count += 1
                if frame_count <= 5:
                    logger.info(f"  - æ¥æ”¶åˆ°ç¬¬ {frame_count} å¹€")
            
            if camera.start_real_time_capture(frame_callback):
                logger.info("âœ“ å³æ™‚æ•ç²å•Ÿå‹•æˆåŠŸ")
                time.sleep(3)  # é‹è¡Œ3ç§’
                camera.stop_real_time_capture()
                logger.info("âœ“ å³æ™‚æ•ç²åœæ­¢æˆåŠŸ")
                
                # æª¢æŸ¥æ€§èƒ½çµ±è¨ˆ
                stats = camera.get_performance_stats()
                logger.info(f"âœ“ æ€§èƒ½çµ±è¨ˆ: FPS={stats.fps:.1f}, ç¸½å¹€æ•¸={stats.frame_count}")
            else:
                logger.error("âœ— å³æ™‚æ•ç²å•Ÿå‹•å¤±æ•—")
            
            camera.release()
            logger.info("âœ“ æ”åƒé ­è³‡æºé‡‹æ”¾æˆåŠŸ")
            return True
            
        else:
            logger.error("âœ— æ”åƒé ­åˆå§‹åŒ–å¤±æ•—")
            return False
            
    except Exception as e:
        logger.error(f"âœ— æ”åƒé ­ç®¡ç†å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_face_detector():
    """æ¸¬è©¦äººè‡‰æª¢æ¸¬å™¨"""
    logger.info("=== æ¸¬è©¦äººè‡‰æª¢æ¸¬å™¨ ===")
    
    try:
        import cv2
        import numpy as np
        from src.ai_engine.modules.face_detector import FaceDetector, DetectionConfig
        
        # å‰µå»ºæª¢æ¸¬é…ç½®
        config = DetectionConfig(
            enable_dnn=False,  # å…ˆæ¸¬è©¦ Haar Cascade
            confidence_threshold=0.5
        )
        
        # åˆå§‹åŒ–äººè‡‰æª¢æ¸¬å™¨
        detector = FaceDetector(config)
        
        # å‰µå»ºæ¸¬è©¦åœ–åƒï¼ˆåŒ…å«ç°¡å–®çš„äººè‡‰ç‰¹å¾µï¼‰
        test_image = np.ones((400, 400, 3), dtype=np.uint8) * 128
        
        # åœ¨åœ–åƒä¸­ç¹ªè£½ä¸€å€‹ç°¡å–®çš„"äººè‡‰"
        cv2.circle(test_image, (200, 150), 80, (200, 200, 200), -1)  # è‡‰
        cv2.circle(test_image, (180, 130), 10, (0, 0, 0), -1)      # å·¦çœ¼
        cv2.circle(test_image, (220, 130), 10, (0, 0, 0), -1)      # å³çœ¼
        cv2.rectangle(test_image, (195, 160), (205, 170), (0, 0, 0), -1)  # é¼»å­
        cv2.ellipse(test_image, (200, 190), (20, 10), 0, 0, 180, (0, 0, 0), 2)  # å˜´
        
        # æ¸¬è©¦äººè‡‰æª¢æ¸¬
        faces = detector.detect_faces(test_image, method="haar")
        logger.info(f"âœ“ æª¢æ¸¬åˆ° {len(faces)} å¼µäººè‡‰")
        
        if faces:
            for i, face in enumerate(faces):
                logger.info(f"  - äººè‡‰ {i+1}: ä½ç½®=({face.x}, {face.y}), å¤§å°={face.width}x{face.height}")
        
        # æ¸¬è©¦ç¹ªè£½åŠŸèƒ½
        result_image = detector.draw_faces(test_image, faces)
        logger.info("âœ“ äººè‡‰æ¡†ç¹ªè£½æˆåŠŸ")
        
        # æ¸¬è©¦äººè‡‰å€åŸŸæå–
        if faces:
            face_roi = detector.get_face_roi(test_image, faces[0])
            if face_roi is not None:
                logger.info(f"âœ“ äººè‡‰å€åŸŸæå–æˆåŠŸ: å¤§å°={face_roi.shape}")
            else:
                logger.warning("âœ— äººè‡‰å€åŸŸæå–å¤±æ•—")
        
        # ç²å–æ€§èƒ½çµ±è¨ˆ
        stats = detector.get_performance_stats()
        logger.info(f"âœ“ æª¢æ¸¬å™¨æ€§èƒ½çµ±è¨ˆ: {stats}")
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— äººè‡‰æª¢æ¸¬å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_emotion_detector():
    """æ¸¬è©¦æƒ…æ„Ÿæª¢æ¸¬å™¨"""
    logger.info("=== æ¸¬è©¦æƒ…æ„Ÿæª¢æ¸¬å™¨ ===")
    
    try:
        import cv2
        import numpy as np
        from src.ai_engine.emotion_detector import EmotionDetector
        
        # åˆå§‹åŒ–æƒ…æ„Ÿæª¢æ¸¬å™¨
        detector = EmotionDetector()
        
        # å‰µå»ºæ¸¬è©¦äººè‡‰åœ–åƒ
        test_face = np.random.randint(0, 255, (48, 48, 3), dtype=np.uint8)
        
        # æ¸¬è©¦æƒ…æ„Ÿé æ¸¬
        result = detector.predict_emotion_from_image(test_face)
        
        logger.info("âœ“ æƒ…æ„Ÿæª¢æ¸¬æˆåŠŸ")
        logger.info(f"  - ä¸»è¦æƒ…æ„Ÿ: {result['dominant_emotion']}")
        logger.info(f"  - ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        logger.info(f"  - æ‰€æœ‰æƒ…æ„Ÿ: {list(result['emotions'].keys())}")
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— æƒ…æ„Ÿæª¢æ¸¬å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_integration():
    """æ¸¬è©¦ç³»çµ±æ•´åˆ"""
    logger.info("=== æ¸¬è©¦ç³»çµ±æ•´åˆ ===")
    
    try:
        from src.ai_engine.modules.camera_manager import CameraManager, CameraConfig
        from src.ai_engine.modules.face_detector import FaceDetector, DetectionConfig
        from src.ai_engine.emotion_detector import EmotionDetector
        
        # åˆå§‹åŒ–æ‰€æœ‰çµ„ä»¶
        camera_config = CameraConfig(device_id=0, fps=10)  # é™ä½FPSç”¨æ–¼æ¸¬è©¦
        camera = CameraManager(camera_config)
        
        detection_config = DetectionConfig(enable_dnn=False)  # ä½¿ç”¨æ›´å¿«çš„æª¢æ¸¬
        face_detector = FaceDetector(detection_config)
        
        emotion_detector = EmotionDetector()
        
        # æ¸¬è©¦åˆå§‹åŒ–
        if not camera.initialize_camera():
            logger.error("âœ— æ”åƒé ­åˆå§‹åŒ–å¤±æ•—")
            return False
        
        logger.info("âœ“ æ‰€æœ‰çµ„ä»¶åˆå§‹åŒ–æˆåŠŸ")
        
        # æ¸¬è©¦ç«¯åˆ°ç«¯æµç¨‹
        test_frames = 5
        processed_frames = 0
        detected_faces = 0
        detected_emotions = 0
        
        def process_frame(frame):
            nonlocal processed_frames, detected_faces, detected_emotions
            
            try:
                # æª¢æ¸¬äººè‡‰
                faces = face_detector.detect_faces(frame)
                detected_faces += len(faces)
                
                # å°æ¯å€‹äººè‡‰é€²è¡Œæƒ…æ„Ÿæª¢æ¸¬
                for face in faces:
                    face_roi = face_detector.get_face_roi(frame, face)
                    if face_roi is not None:
                        emotion_result = emotion_detector.predict_emotion_from_image(face_roi)
                        if emotion_result['dominant_emotion']:
                            detected_emotions += 1
                
                processed_frames += 1
                logger.info(f"  - è™•ç†ç¬¬ {processed_frames} å¹€: {len(faces)} å¼µäººè‡‰")
                
            except Exception as e:
                logger.error(f"  - å¹€è™•ç†å¤±æ•—: {e}")
        
        # å•Ÿå‹•è™•ç†
        if camera.start_real_time_capture(process_frame):
            logger.info("âœ“ é–‹å§‹ç«¯åˆ°ç«¯æ¸¬è©¦...")
            
            # é‹è¡Œæ¸¬è©¦
            start_time = time.time()
            while processed_frames < test_frames and time.time() - start_time < 10:
                time.sleep(0.1)
            
            camera.stop_real_time_capture()
            
            # çµ±è¨ˆçµæœ
            runtime = time.time() - start_time
            logger.info(f"âœ“ ç«¯åˆ°ç«¯æ¸¬è©¦å®Œæˆ")
            logger.info(f"  - è™•ç†æ™‚é–“: {runtime:.2f}s")
            logger.info(f"  - è™•ç†å¹€æ•¸: {processed_frames}")
            logger.info(f"  - æª¢æ¸¬äººè‡‰: {detected_faces}")
            logger.info(f"  - æƒ…æ„Ÿæª¢æ¸¬: {detected_emotions}")
            logger.info(f"  - å¹³å‡FPS: {processed_frames/runtime:.2f}")
            
            # æ€§èƒ½é©—è­‰
            camera_stats = camera.get_performance_stats()
            detector_stats = face_detector.get_performance_stats()
            
            logger.info(f"âœ“ æ”åƒé ­æ€§èƒ½: FPS={camera_stats.fps:.1f}")
            logger.info(f"âœ“ æª¢æ¸¬å™¨æ€§èƒ½: FPS={detector_stats['detection_fps']:.1f}")
            
            camera.release()
            return True
            
        else:
            logger.error("âœ— ç„¡æ³•å•Ÿå‹•å³æ™‚æ•ç²")
            camera.release()
            return False
            
    except Exception as e:
        logger.error(f"âœ— ç³»çµ±æ•´åˆæ¸¬è©¦å¤±æ•—: {e}")
        return False


def performance_benchmark():
    """æ€§èƒ½åŸºæº–æ¸¬è©¦"""
    logger.info("=== æ€§èƒ½åŸºæº–æ¸¬è©¦ ===")
    
    try:
        from src.ai_engine.modules.camera_manager import CameraManager, CameraConfig
        from src.ai_engine.modules.face_detector import FaceDetector, DetectionConfig
        from src.ai_engine.emotion_detector import EmotionDetector
        
        # é…ç½®
        target_fps = 24
        target_latency = 0.1  # 100ms
        test_duration = 10    # 10ç§’
        
        # åˆå§‹åŒ–çµ„ä»¶
        camera = CameraManager(CameraConfig(fps=30))
        face_detector = FaceDetector(DetectionConfig(enable_dnn=False))
        emotion_detector = EmotionDetector()
        
        if not camera.initialize_camera():
            logger.error("âœ— æ”åƒé ­åˆå§‹åŒ–å¤±æ•—")
            return False
        
        # æ€§èƒ½çµ±è¨ˆ
        frame_times = []
        detection_times = []
        emotion_times = []
        total_faces = 0
        total_emotions = 0
        
        def benchmark_frame(frame):
            nonlocal total_faces, total_emotions
            
            frame_start = time.time()
            
            # äººè‡‰æª¢æ¸¬
            detect_start = time.time()
            faces = face_detector.detect_faces(frame)
            detect_time = time.time() - detect_start
            detection_times.append(detect_time)
            total_faces += len(faces)
            
            # æƒ…æ„Ÿæª¢æ¸¬
            for face in faces:
                emotion_start = time.time()
                face_roi = face_detector.get_face_roi(frame, face)
                if face_roi is not None:
                    emotion_detector.predict_emotion_from_image(face_roi)
                    total_emotions += 1
                emotion_time = time.time() - emotion_start
                emotion_times.append(emotion_time)
            
            frame_time = time.time() - frame_start
            frame_times.append(frame_time)
        
        # åŸ·è¡ŒåŸºæº–æ¸¬è©¦
        camera.start_real_time_capture(benchmark_frame)
        logger.info(f"âœ“ é–‹å§‹ {test_duration} ç§’æ€§èƒ½æ¸¬è©¦...")
        
        time.sleep(test_duration)
        camera.stop_real_time_capture()
        camera.release()
        
        # åˆ†æçµæœ
        if frame_times:
            avg_frame_time = sum(frame_times) / len(frame_times)
            actual_fps = 1.0 / avg_frame_time
            
            avg_detection_time = sum(detection_times) / len(detection_times) if detection_times else 0
            avg_emotion_time = sum(emotion_times) / len(emotion_times) if emotion_times else 0
            
            logger.info(f"âœ“ æ€§èƒ½æ¸¬è©¦çµæœ:")
            logger.info(f"  - ç¸½è™•ç†å¹€æ•¸: {len(frame_times)}")
            logger.info(f"  - å¹³å‡å¹€è™•ç†æ™‚é–“: {avg_frame_time:.3f}s")
            logger.info(f"  - å¯¦éš›FPS: {actual_fps:.1f}")
            logger.info(f"  - äººè‡‰æª¢æ¸¬æ™‚é–“: {avg_detection_time:.3f}s")
            logger.info(f"  - æƒ…æ„Ÿæª¢æ¸¬æ™‚é–“: {avg_emotion_time:.3f}s")
            logger.info(f"  - ç¸½æª¢æ¸¬äººè‡‰: {total_faces}")
            logger.info(f"  - ç¸½æƒ…æ„Ÿæª¢æ¸¬: {total_emotions}")
            
            # æ€§èƒ½è©•ä¼°
            fps_ok = actual_fps >= target_fps
            latency_ok = avg_frame_time <= target_latency
            
            logger.info(f"âœ“ æ€§èƒ½è©•ä¼°:")
            logger.info(f"  - FPSé”æ¨™: {'âœ“' if fps_ok else 'âœ—'} (ç›®æ¨™: {target_fps}, å¯¦éš›: {actual_fps:.1f})")
            logger.info(f"  - å»¶é²é”æ¨™: {'âœ“' if latency_ok else 'âœ—'} (ç›®æ¨™: {target_latency:.3f}s, å¯¦éš›: {avg_frame_time:.3f}s)")
            
            return fps_ok and latency_ok
        else:
            logger.error("âœ— æ²’æœ‰æ”¶é›†åˆ°æ€§èƒ½æ•¸æ“š")
            return False
            
    except Exception as e:
        logger.error(f"âœ— æ€§èƒ½åŸºæº–æ¸¬è©¦å¤±æ•—: {e}")
        return False


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    logger.info("LivePilotAI Day 4 åŠŸèƒ½æ¸¬è©¦é–‹å§‹")
    logger.info("=" * 50)
    
    test_results = {
        "æ”åƒé ­ç®¡ç†å™¨": False,
        "äººè‡‰æª¢æ¸¬å™¨": False,
        "æƒ…æ„Ÿæª¢æ¸¬å™¨": False,
        "ç³»çµ±æ•´åˆ": False,
        "æ€§èƒ½åŸºæº–": False
    }
    
    # åŸ·è¡Œå„é …æ¸¬è©¦
    test_results["æ”åƒé ­ç®¡ç†å™¨"] = test_camera_manager()
    test_results["äººè‡‰æª¢æ¸¬å™¨"] = test_face_detector()
    test_results["æƒ…æ„Ÿæª¢æ¸¬å™¨"] = test_emotion_detector()
    
    # åªæœ‰åŸºç¤æ¸¬è©¦é€šéæ‰é€²è¡Œæ•´åˆæ¸¬è©¦
    if all([test_results["æ”åƒé ­ç®¡ç†å™¨"], test_results["äººè‡‰æª¢æ¸¬å™¨"], test_results["æƒ…æ„Ÿæª¢æ¸¬å™¨"]]):
        test_results["ç³»çµ±æ•´åˆ"] = test_integration()
        
        # åªæœ‰æ•´åˆæ¸¬è©¦é€šéæ‰é€²è¡Œæ€§èƒ½æ¸¬è©¦
        if test_results["ç³»çµ±æ•´åˆ"]:
            test_results["æ€§èƒ½åŸºæº–"] = performance_benchmark()
    
    # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
    logger.info("=" * 50)
    logger.info("Day 4 æ¸¬è©¦çµæœç¸½çµ:")
    
    passed_tests = 0
    for test_name, result in test_results.items():
        status = "âœ“ é€šé" if result else "âœ— å¤±æ•—"
        logger.info(f"  - {test_name}: {status}")
        if result:
            passed_tests += 1
    
    total_tests = len(test_results)
    success_rate = (passed_tests / total_tests) * 100
    
    logger.info(f"ç¸½é«”æ¸¬è©¦çµæœ: {passed_tests}/{total_tests} é€šé ({success_rate:.1f}%)")
    
    if success_rate >= 80:
        logger.info("ğŸ‰ Day 4 ä»»å‹™å®Œæˆåº¦: å„ªç§€!")
    elif success_rate >= 60:
        logger.info("ğŸ˜Š Day 4 ä»»å‹™å®Œæˆåº¦: è‰¯å¥½!")
    else:
        logger.info("âš ï¸  Day 4 ä»»å‹™éœ€è¦æ”¹é€²")
    
    return success_rate >= 60


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        logger.error(f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        sys.exit(1)
