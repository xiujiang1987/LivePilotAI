import sys
import os
from pathlib import Path

# è¨­ç½®è·¯å¾‘
project_root = Path.cwd()
sys.path.insert(0, str(project_root / 'src'))

print('ğŸ¬ LivePilotAI å¯¦ä¾‹æ¸¬è©¦é–‹å§‹')
print('=' * 50)

# æ¸¬è©¦ 1: åŸºæœ¬åº«
try:
    import cv2
    import numpy as np
    print(f'âœ… OpenCV: {cv2.__version__}')
    print(f'âœ… NumPy: {np.__version__}')
except Exception as e:
    print(f'âŒ åŸºæœ¬åº«å¤±æ•—: {e}')
    sys.exit(1)

# æ¸¬è©¦ 2: å°ˆæ¡ˆæ¨¡çµ„
try:
    from ai_engine.modules.camera_manager import CameraManager, CameraConfig
    from ai_engine.modules.face_detector import FaceDetector, DetectionConfig
    from ai_engine.emotion_detector import EmotionDetector
    print('âœ… æ‰€æœ‰å°ˆæ¡ˆæ¨¡çµ„å°å…¥æˆåŠŸ')
except Exception as e:
    print(f'âŒ å°ˆæ¡ˆæ¨¡çµ„å¤±æ•—: {e}')
    import traceback
    traceback.print_exc()
    sys.exit(1)

# æ¸¬è©¦ 3: å¯¦ä¾‹åŒ–
try:
    config = CameraConfig(device_id=0, width=640, height=480, fps=30)
    camera = CameraManager(config)
    
    detection_config = DetectionConfig(detection_method='haar', min_face_size=(30, 30))
    face_detector = FaceDetector(detection_config)
    
    emotion_detector = EmotionDetector()
    
    print('âœ… æ‰€æœ‰æ¨¡çµ„å¯¦ä¾‹åŒ–æˆåŠŸ')
except Exception as e:
    print(f'âŒ å¯¦ä¾‹åŒ–å¤±æ•—: {e}')
    import traceback
    traceback.print_exc()
    sys.exit(1)

# æ¸¬è©¦ 4: æ”åƒé ­
try:
    cap = cv2.VideoCapture(0)
    if cap.isOpened():
        ret, frame = cap.read()
        if ret:
            print(f'âœ… æ”åƒé ­å·¥ä½œæ­£å¸¸ï¼Œå¹€å¤§å°: {frame.shape}')
            camera_ready = True
        else:
            print('âš ï¸ æ”åƒé ­ç„¡æ³•è®€å–å¹€')
            camera_ready = False
        cap.release()
    else:
        print('âš ï¸ æ”åƒé ­ä¸å¯ç”¨')
        camera_ready = False
except Exception as e:
    print(f'âš ï¸ æ”åƒé ­æ¸¬è©¦å¤±æ•—: {e}')
    camera_ready = False

print('\nğŸ‰ åŸºç¤æ¸¬è©¦å®Œæˆï¼')
print('ğŸ“‹ æ¸¬è©¦çµæœ:')
print('  â€¢ åŸºæœ¬åº«: âœ… æ­£å¸¸')
print('  â€¢ å°ˆæ¡ˆæ¨¡çµ„: âœ… æ­£å¸¸')
print('  â€¢ æ¨¡çµ„å¯¦ä¾‹åŒ–: âœ… æ­£å¸¸')
print(f'  â€¢ æ”åƒé ­: {"âœ… å°±ç·’" if camera_ready else "âš ï¸ ä¸å¯ç”¨"}')

if camera_ready:
    print('\nğŸš€ ç³»çµ±å®Œå…¨å°±ç·’ï¼Œå¯ä»¥é–‹å§‹å³æ™‚æª¢æ¸¬æ¸¬è©¦ï¼')
    user_input = input('\nğŸ’¡ æ˜¯å¦å•Ÿå‹•å³æ™‚æª¢æ¸¬æ¼”ç¤ºï¼Ÿ(y/n): ').lower().strip()
    if user_input in ['y', 'yes']:
        print('ğŸ¬ æ­£åœ¨å•Ÿå‹•å³æ™‚æª¢æ¸¬...')
        print('ğŸ’¡ è«‹ç¢ºä¿æ‚¨çš„è‡‰éƒ¨åœ¨æ”åƒé ­è¦–é‡å…§')
        print('âŒ¨ï¸ æ“ä½œæç¤º: æŒ‰ q éµé€€å‡ºï¼ŒæŒ‰ s éµæˆªåœ–')
        
        # å•Ÿå‹•å³æ™‚æª¢æ¸¬
        try:
            from ai_engine.modules.real_time_detector import RealTimeEmotionDetector, RealTimeConfig
            
            rt_config = RealTimeConfig(
                camera_device_id=0,
                camera_width=640,
                camera_height=480,
                target_fps=30,
                detection_method='haar',
                show_fps=True,
                show_confidence=True
            )
            
            detector = RealTimeEmotionDetector(rt_config)
            print('âœ… å³æ™‚æª¢æ¸¬å™¨åˆå§‹åŒ–æˆåŠŸ')
            
            # 3ç§’å€’æ•¸
            import time
            for i in range(3, 0, -1):
                print(f'â° {i}ç§’å¾Œé–‹å§‹...')
                time.sleep(1)
            
            detector.start_detection()
            detector.wait_for_completion()
            
        except KeyboardInterrupt:
            print('\nâ¹ï¸ ç”¨æˆ¶ä¸­æ–·æª¢æ¸¬')
        except Exception as e:
            print(f'\nâŒ å³æ™‚æª¢æ¸¬å¤±æ•—: {e}')
            import traceback
            traceback.print_exc()
        finally:
            try:
                detector.stop_detection()
            except:
                pass
            print('ğŸ›‘ æª¢æ¸¬å·²åœæ­¢')
    else:
        print('ğŸ“Š æ¸¬è©¦å®Œæˆï¼Œç³»çµ±å·²å°±ç·’')
else:
    print('\nğŸ“Š åŸºç¤åŠŸèƒ½æ¸¬è©¦å®Œæˆ')
    print('ğŸ’¡ æ”åƒé ­ä¸å¯ç”¨ï¼Œä½†æ ¸å¿ƒåŠŸèƒ½å·²é©—è­‰æ­£å¸¸')

print('\nğŸŠ LivePilotAI å¯¦ä¾‹æ¸¬è©¦å®Œæˆï¼')
