#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LivePilotAI æ ¸å¿ƒåŠŸèƒ½å¯¦æ™‚æ¸¬è©¦
ç°¡åŒ–ç‰ˆæœ¬ï¼Œå°ˆæ³¨æ–¼é©—è­‰æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸é‹ä½œ
"""

import cv2
import sys
import time
from pathlib import Path

# è¨­ç½®è·¯å¾‘
sys.path.insert(0, str(Path.cwd() / 'src'))

print("ğŸ­ LivePilotAI æ ¸å¿ƒåŠŸèƒ½å¯¦æ™‚æ¸¬è©¦")
print("=" * 40)

def test_basic_camera():
    """åŸºæœ¬æ”åƒé ­æ¸¬è©¦"""
    print("ğŸ“· åŸºæœ¬æ”åƒé ­æ¸¬è©¦...")
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("âŒ æ”åƒé ­ç„¡æ³•é–‹å•Ÿ")
        return False
    
    print("âœ… æ”åƒé ­å·²é–‹å•Ÿ")
    
    # è®€å–å¹¾å¹€æ¸¬è©¦
    for i in range(5):
        ret, frame = cap.read()
        if ret:
            print(f"âœ… æˆåŠŸè®€å–ç¬¬ {i+1} å¹€ï¼Œå°ºå¯¸: {frame.shape}")
        else:
            print(f"âŒ ç„¡æ³•è®€å–ç¬¬ {i+1} å¹€")
            cap.release()
            return False
    
    cap.release()
    print("âœ… åŸºæœ¬æ”åƒé ­æ¸¬è©¦é€šé")
    return True

def test_face_detection():
    """åŸºæœ¬äººè‡‰æª¢æ¸¬æ¸¬è©¦"""
    print("\nğŸ‘¤ åŸºæœ¬äººè‡‰æª¢æ¸¬æ¸¬è©¦...")
    
    try:
        # ä½¿ç”¨ OpenCV å…§å»ºçš„äººè‡‰æª¢æ¸¬
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("âŒ æ”åƒé ­ç„¡æ³•é–‹å•Ÿ")
            return False
        
        print("âœ… äººè‡‰æª¢æ¸¬å™¨å·²è¼‰å…¥")
        print("ğŸ¥ é–‹å§‹ 5 ç§’äººè‡‰æª¢æ¸¬æ¸¬è©¦...")
        
        start_time = time.time()
        frame_count = 0
        face_count = 0
        
        while time.time() - start_time < 5:  # æ¸¬è©¦ 5 ç§’
            ret, frame = cap.read()
            if not ret:
                continue
                
            frame_count += 1
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # æª¢æ¸¬äººè‡‰
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            if len(faces) > 0:
                face_count += 1
                print(f"âœ… å¹€ {frame_count}: æª¢æ¸¬åˆ° {len(faces)} å€‹äººè‡‰")
            
            # ç¹ªè£½äººè‡‰æ¡†
            for (x, y, w, h) in faces:
                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
            
            # é¡¯ç¤ºçµ±è¨ˆ
            cv2.putText(frame, f'Frames: {frame_count}', (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(frame, f'Faces: {len(faces)}', (10, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(frame, f'Test: {5-(time.time()-start_time):.1f}s', (10, 90), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            cv2.imshow('Face Detection Test', frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
        
        print(f"ğŸ“Š æ¸¬è©¦çµæœ:")
        print(f"   ç¸½å¹€æ•¸: {frame_count}")
        print(f"   æª¢æ¸¬åˆ°äººè‡‰çš„å¹€æ•¸: {face_count}")
        print(f"   æª¢æ¸¬ç‡: {(face_count/frame_count*100):.1f}%" if frame_count > 0 else "N/A")
        
        return True
        
    except Exception as e:
        print(f"âŒ äººè‡‰æª¢æ¸¬æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_emotion_modules():
    """æ¸¬è©¦æƒ…æ„Ÿæª¢æ¸¬æ¨¡çµ„"""
    print("\nğŸ­ æƒ…æ„Ÿæª¢æ¸¬æ¨¡çµ„æ¸¬è©¦...")
    
    try:
        from ai_engine.emotion_detector import EmotionDetector
        emotion_detector = EmotionDetector()
        print("âœ… EmotionDetector æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
        
        # æ¸¬è©¦æ¨¡çµ„æ–¹æ³•
        if hasattr(emotion_detector, 'predict_emotion_from_image'):
            print("âœ… predict_emotion_from_image æ–¹æ³•å¯ç”¨")
        else:
            print("âŒ predict_emotion_from_image æ–¹æ³•ä¸å¯ç”¨")
            
        return True
        
    except Exception as e:
        print(f"âŒ æƒ…æ„Ÿæª¢æ¸¬æ¨¡çµ„æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æ¸¬è©¦æµç¨‹"""
    print("é–‹å§‹æ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦...")
    
    # 1. åŸºæœ¬æ”åƒé ­æ¸¬è©¦
    camera_ok = test_basic_camera()
    
    # 2. äººè‡‰æª¢æ¸¬æ¸¬è©¦
    face_ok = test_face_detection() if camera_ok else False
    
    # 3. æƒ…æ„Ÿæª¢æ¸¬æ¨¡çµ„æ¸¬è©¦
    emotion_ok = test_emotion_modules()
    
    # ç¸½çµ
    print(f"\nğŸ“Š æ¸¬è©¦ç¸½çµ:")
    print(f"   æ”åƒé ­: {'âœ… é€šé' if camera_ok else 'âŒ å¤±æ•—'}")
    print(f"   äººè‡‰æª¢æ¸¬: {'âœ… é€šé' if face_ok else 'âŒ å¤±æ•—'}")
    print(f"   æƒ…æ„Ÿæ¨¡çµ„: {'âœ… é€šé' if emotion_ok else 'âŒ å¤±æ•—'}")
    
    if all([camera_ok, face_ok, emotion_ok]):
        print("\nğŸ‰ æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦é€šéï¼")
        print("ğŸ’¡ ç³»çµ±å·²å°±ç·’ï¼Œå¯ä»¥é‹è¡Œå®Œæ•´æ¸¬è©¦")
    else:
        print("\nâš ï¸ éƒ¨åˆ†åŠŸèƒ½æ¸¬è©¦å¤±æ•—")
    
    return all([camera_ok, face_ok, emotion_ok])

if __name__ == "__main__":
    try:
        success = main()
        print(f"\n{'='*40}")
        print("æ¸¬è©¦å®Œæˆï¼" if success else "æ¸¬è©¦ç™¼ç¾å•é¡Œï¼")
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ¶ä¸­æ–·æ¸¬è©¦")
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹å‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()
