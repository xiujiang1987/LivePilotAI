# -*- coding: utf-8 -*-
"""
LivePilotAI è‡ªä¸»æ•´åˆæ¸¬è©¦
é©—è­‰ AI Director èˆ‡ RealTimeEmotionDetector çš„æ•´åˆæ€§
"""
import sys
import os
import time
import numpy as np
from pathlib import Path

# Setup path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'src'))

def test_integration():
    print("ğŸš€ é–‹å§‹è‡ªä¸»æ•´åˆæ¸¬è©¦...")
    
    # 1. æ¸¬è©¦ä¾è³´æª¢æŸ¥
    print("\n[1/3] æª¢æŸ¥ä¾è³´å¥—ä»¶...")
    try:
        import speech_recognition
        import mediapipe
        import pyaudio
        print("  âœ… é—œéµå¥—ä»¶ (SpeechRecognition, MediaPipe, PyAudio) å·²å®‰è£")
    except ImportError as e:
        print(f"  âŒ ç¼ºå°‘å¥—ä»¶: {e}")
        return False

    # 2. æ¸¬è©¦ AI Director åˆå§‹åŒ– (å¤§è…¦)
    print("\n[2/3] åˆå§‹åŒ– AI Director (å¤§è…¦)...")
    try:
        from ai_engine.modules.ai_director import AIDirector
        director = AIDirector()
        print("  âœ… AIDirector åˆå§‹åŒ–æˆåŠŸ")
        print(f"  â„¹ï¸  è¼‰å…¥è¦å‰‡æ•¸: {len(director.rules)}")
    except Exception as e:
        print(f"  âŒ AIDirector æ•…éšœ: {e}")
        return False

    # 3. æ¸¬è©¦åµæ¸¬å™¨æ•´åˆ (çœ¼ç› -> å¤§è…¦)
    print("\n[3/3] æ¸¬è©¦ç¥ç¶“æ•´åˆ (Simulated)...")
    try:
        # Mock frame (black image)
        mock_frame = np.zeros((480, 640, 3), dtype=np.uint8)
        
        # Test processing
        decision, metadata = director.process_frame(mock_frame)
        print(f"  âœ… è™•ç†å½±æ ¼æˆåŠŸ via AIDirector")
        print(f"  â„¹ï¸  Metadata: {metadata.keys()}")
        print(f"  â„¹ï¸  Decision: {decision}")
        
    except Exception as e:
        print(f"  âŒ æ•´åˆæ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

    print("\nâœ¨ æ¸¬è©¦å®Œæˆ: ç³»çµ±é‚è¼¯æ ¸å¿ƒé‹ä½œæ­£å¸¸")
    return True

if __name__ == "__main__":
    success = test_integration()
    sys.exit(0 if success else 1)
