import cv2
import sys
import time
from pathlib import Path

# è¨­ç½®è·¯å¾‘
sys.path.insert(0, str(Path.cwd() / 'src'))

print("ğŸ­ LivePilotAI å®Œæ•´æƒ…æ„Ÿæª¢æ¸¬æ¸¬è©¦")
print("=" * 50)

try:
    # å°å…¥æ‰€æœ‰æ¨¡çµ„
    from ai_engine.modules.camera_manager import CameraManager, CameraConfig
    from ai_engine.modules.face_detector import FaceDetector, DetectionConfig
    from ai_engine.emotion_detector import EmotionDetector
    print("âœ… æ‰€æœ‰æ¨¡çµ„å°å…¥æˆåŠŸ")
    
    # å‰µå»ºé…ç½®
    camera_config = CameraConfig(
        device_id=0,
        width=640,
        height=480,
        fps=30
    )
    
    detection_config = DetectionConfig(
        detection_method='haar',
        min_face_size=(30, 30),
        scale_factor=1.1,
        min_neighbors=5
    )
    
    # åˆå§‹åŒ–çµ„ä»¶
    camera_manager = CameraManager(camera_config)
    face_detector = FaceDetector(detection_config)
    emotion_detector = EmotionDetector()
    
    print("âœ… æ‰€æœ‰çµ„ä»¶åˆå§‹åŒ–æˆåŠŸ")
    
    # æª¢æŸ¥æ”åƒé ­
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ æ”åƒé ­ä¸å¯ç”¨")
        exit()
    
    print("âœ… æ”åƒé ­å·²å•Ÿå‹•")
    print("\nğŸ¬ é–‹å§‹å®Œæ•´æƒ…æ„Ÿæª¢æ¸¬æ¸¬è©¦...")
    print("ğŸ’¡ åŠŸèƒ½èªªæ˜:")
    print("   - å³æ™‚äººè‡‰æª¢æ¸¬")
    print("   - 7ç¨®æƒ…æ„Ÿè­˜åˆ¥ (å¿«æ¨‚ã€æ‚²å‚·ã€æ†¤æ€’ã€ææ‡¼ã€é©šè¨ã€å­æƒ¡ã€ä¸­æ€§)")
    print("   - å¯¦æ™‚æ€§èƒ½ç›£æ§")
    print("\nâŒ¨ï¸ æ“ä½œèªªæ˜:")
    print("   - æŒ‰ 'q' éµé€€å‡º")
    print("   - æŒ‰ 's' éµæˆªåœ–")
    print("   - æŒ‰ 'SPACE' éµæš«åœ/æ¢å¾©")
    
    # æ€§èƒ½çµ±è¨ˆ
    frame_count = 0
    start_time = time.time()
    paused = False
    
    # æƒ…æ„Ÿæ¨™ç±¤æ˜ å°„
    emotion_labels = {
        0: 'ğŸ˜  Angry',
        1: 'ğŸ¤¢ Disgust', 
        2: 'ğŸ˜¨ Fear',
        3: 'ğŸ˜Š Happy',
        4: 'ğŸ˜ Neutral',
        5: 'ğŸ˜¢ Sad',
        6: 'ğŸ˜® Surprise'
    }
    
    # é¡è‰²æ˜ å°„ (BGR)
    emotion_colors = {
        0: (0, 0, 255),      # æ†¤æ€’ - ç´…è‰²
        1: (0, 128, 128),    # å­æƒ¡ - é’è‰²
        2: (128, 0, 128),    # ææ‡¼ - ç´«è‰²
        3: (0, 255, 0),      # å¿«æ¨‚ - ç¶ è‰²
        4: (128, 128, 128),  # ä¸­æ€§ - ç°è‰²
        5: (255, 0, 0),      # æ‚²å‚· - è—è‰²
        6: (0, 255, 255)     # é©šè¨ - é»ƒè‰²
    }
    
    print(f"\nâ° 3ç§’å¾Œé–‹å§‹æª¢æ¸¬...")
    for i in range(3, 0, -1):
        print(f"   {i}...")
        time.sleep(1)
    print("ğŸš€ é–‹å§‹æª¢æ¸¬ï¼")
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                print("âŒ ç„¡æ³•è®€å–æ”åƒé ­ç•«é¢")
                break
            
            frame_count += 1
            current_time = time.time()
            fps = frame_count / (current_time - start_time) if current_time > start_time else 0
            
            try:
                # æª¢æ¸¬äººè‡‰
                face_detections = face_detector.detect_faces(frame)
                
                # è™•ç†æ¯å€‹æª¢æ¸¬åˆ°çš„äººè‡‰
                for detection in face_detections:
                    x, y, w, h = detection.bbox
                    confidence = detection.confidence
                    
                    # æå–äººè‡‰å€åŸŸ
                    face_roi = frame[y:y+h, x:x+w]
                    
                    if face_roi.size > 0:
                        # æƒ…æ„Ÿæª¢æ¸¬
                        try:
                            emotion_result = emotion_detector.predict_emotion_from_image(face_roi)
                            emotion_idx = emotion_result['predicted_emotion']
                            emotion_confidence = emotion_result['confidence']
                            
                            # ç²å–é¡è‰²å’Œæ¨™ç±¤
                            color = emotion_colors.get(emotion_idx, (255, 255, 255))
                            label = emotion_labels.get(emotion_idx, f'Unknown ({emotion_idx})')
                            
                            # ç¹ªè£½äººè‡‰æ¡†
                            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
                            
                            # é¡¯ç¤ºæƒ…æ„Ÿæ¨™ç±¤å’Œä¿¡å¿ƒåº¦
                            emotion_text = f'{label} ({emotion_confidence:.2f})'
                            cv2.putText(frame, emotion_text, (x, y-10), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                            
                            # é¡¯ç¤ºäººè‡‰æª¢æ¸¬ä¿¡å¿ƒåº¦
                            face_text = f'Face: {confidence:.2f}'
                            cv2.putText(frame, face_text, (x, y+h+20), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
                            
                        except Exception as e:
                            # å¦‚æœæƒ…æ„Ÿæª¢æ¸¬å¤±æ•—ï¼Œåªé¡¯ç¤ºäººè‡‰æ¡†
                            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                            cv2.putText(frame, f'Face ({confidence:.2f})', (x, y-10), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                            cv2.putText(frame, f'Emotion Error: {str(e)[:20]}', (x, y+h+20), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 255), 1)
                
                # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
                stats_y = 30
                cv2.putText(frame, f'Faces: {len(face_detections)}', (10, stats_y), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.putText(frame, f'FPS: {fps:.1f}', (10, stats_y + 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.putText(frame, f'Frame: {frame_count}', (10, stats_y + 60), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
            except Exception as e:
                print(f"âš ï¸ æª¢æ¸¬éç¨‹å‡ºéŒ¯: {e}")
                cv2.putText(frame, f"Detection Error", (10, 90), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        else:
            # æš«åœç‹€æ…‹
            cv2.putText(frame, "PAUSED - Press SPACE to resume", 
                       (frame.shape[1]//2 - 150, frame.shape[0]//2), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        
        # é¡¯ç¤ºæ“ä½œæç¤º
        help_y = frame.shape[0] - 60
        cv2.putText(frame, "q:Quit | s:Save | SPACE:Pause", (10, help_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(frame, "LivePilotAI - Emotion Detection Test", (10, help_y + 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # é¡¯ç¤ºçµæœ
        cv2.imshow('LivePilotAI - Complete Emotion Detection Test', frame)
        
        # è™•ç†æŒ‰éµ
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            print("ğŸ‘‹ ç”¨æˆ¶é€€å‡ºæ¸¬è©¦")
            break
        elif key == ord('s'):
            filename = f'emotion_test_{int(time.time())}.jpg'
            cv2.imwrite(filename, frame)
            print(f"ğŸ“¸ æˆªåœ–å·²ä¿å­˜: {filename}")
        elif key == ord(' '):  # ç©ºæ ¼éµ
            paused = not paused
            print(f"â¸ï¸ æ¸¬è©¦{'æš«åœ' if paused else 'æ¢å¾©'}")
    
    # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
    total_time = time.time() - start_time
    avg_fps = frame_count / total_time if total_time > 0 else 0
    
    print(f"\nğŸ“Š æ¸¬è©¦çµ±è¨ˆ:")
    print(f"   ç¸½å¹€æ•¸: {frame_count}")
    print(f"   ç¸½æ™‚é–“: {total_time:.1f} ç§’")
    print(f"   å¹³å‡ FPS: {avg_fps:.1f}")
    
    cap.release()
    cv2.destroyAllWindows()
    print("ğŸ‰ å®Œæ•´æƒ…æ„Ÿæª¢æ¸¬æ¸¬è©¦å®Œæˆï¼")
    
except Exception as e:
    print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
    import traceback
    traceback.print_exc()
finally:
    try:
        cap.release()
        cv2.destroyAllWindows()
    except:
        pass
